{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spark to do Anamoly predictions for streaming data\n",
    "We well use spark and a simple anomoly detector to look at the data from 30 different instrument streams coming through Kinesis.   We use Spark instead of Spark Streaming for two reasons.  First the Kinesis connector for Spark is somewhat unreliable and we want to do the anaomoly detection explicitly in the notebook.  \n",
    "\n",
    "The data set being used here is based on a 24 hour sample of event streams of about 40 instruments similar to the ones used in the Chicago Array of Things project.  This data set is available for download.  A seperate program is used to read the dataset and push the events as fast as possible to Kinesis.   With one shard we can push the full collection of events to Kinesis in 40 minutes.  \n",
    "\n",
    "## setup\n",
    "To use this notebook you need an AWS account and a Kinesis stream.   There are several invironments in which this will run \n",
    "<ul>\n",
    "<li> the jupyter/all-spark-notebook.   \n",
    "<li> The Azure linux DataScienceVM.\n",
    "</ul>\n",
    "## jupyter/all-spark-notebook\n",
    "you can run it with the following command\n",
    "\n",
    "docker run -it --rm -p 8888:8888  -v path-to-your-notebooks:/notebooks jupyter/all-spark-notebook\n",
    "\n",
    "The path to your notebooks is where you keep a copy of this notebook.\n",
    "\n",
    "You will also need you AWS crentials.   If you are running on your own machine can avoid loading your credentials explicitly of you can add a \n",
    "\n",
    "-v path-to-your-.aws:.aws\n",
    "\n",
    "to the above docker command.\n",
    "You will also need to install boto3 and tzlocal.  see below.\n",
    "Finally you will need the spark context object sc -  again see below.\n",
    "## Azure linux DataScienceVM\n",
    "For this you are likely going to come in through JupyterHub at http://yourmIP:8000\n",
    "You will need to have the manager of the VM do the boto3 install and then you will need to do it locally.  have that person execute the following \n",
    "\n",
    "sudo /anaconda/envs/py35/bin/pip install boto3\n",
    "\n",
    "sudo /anaconda/bin/pip install boto3\n",
    "\n",
    "and do the same with tzlocal. Then you need to do it one more time as shown below.\n",
    "you will still need to  upload this notebook and you will need to have your aws credentials.\n",
    "\n",
    "When you load the notebook into Jupyter make sure you run with the kernel Spark-python. you can set it from the Kernel dropdown menu.\n",
    "\n",
    "## The data to send to Kinesis\n",
    "The data and a program to send the data to Kinesis is in the directory kinesis-spark-AoT in the same place where you found this.  You need to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is where you need to install boto3 and tzlocal\n",
    "#if you are running in the azure datascienceVM uncomment these two lines\n",
    "#!/anaconda/bin/pip install boto3\n",
    "#!/anaconda/bin/pip install tzlocal\n",
    "\n",
    "#if you are running Jupyter/all-spark-notebook then uncomment these two lines\n",
    "#!pip install boto3\n",
    "#!pip install tzlocal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import datetime\n",
    "from tzlocal import get_localzone\n",
    "import pytz\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from pylab import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure we have the Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If you are running in the Azure linux datascienceVM with the Spark-python kernel \n",
    "#you do not have do do anything.  you should already have the spark context as sc as shown below\n",
    "#if you are running in the Jupyter/all-spark-notebook you need to run these\n",
    "#two lines\n",
    "#from pyspark import SparkContext\n",
    "#sc= SparkContext('local', 'pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://datasciencevm.internal.cloudapp.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish  Kinesis connection\n",
    "The following code will create a list of interators: one for each shard of the Kinesis stream.  Normally we would run a seperate thread for each shard, but this allows us to treat all shards directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#client = boto3.client('kinesis')\n",
    "#you may need to do the full boto3 client initialization.  if so it is\n",
    "client = boto3.client('kinesis', region_name = 'ap-northeast-1',\n",
    "                     aws_access_key_id = 'AKIA4OIB5R45V26BEIOO',\n",
    "                     aws_secret_access_key = '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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "resp = client.describe_stream(StreamName='cloudbook2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ShardId': 'shardId-000000000000',\n",
       "  'HashKeyRange': {'StartingHashKey': '0',\n",
       "   'EndingHashKey': '340282366920938463463374607431768211455'},\n",
       "  'SequenceNumberRange': {'StartingSequenceNumber': '49620278587119386474195422998226360013264737056925417474'}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp['StreamDescription']['Shards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shardlist = []\n",
    "startkeys = []\n",
    "for shard in resp['StreamDescription']['Shards']:\n",
    "    shardlist.append({'ShardId':shard['ShardId'], 'seqno':shard['SequenceNumberRange']['StartingSequenceNumber']})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the stream cloudbook2 has only one shard.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ShardId': 'shardId-000000000000',\n",
       "  'seqno': '49620278587119386474195422998226360013264737056925417474'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shardlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterlist below will be our list of iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "iterlist = []\n",
    "for shard in shardlist:\n",
    "    iter = client.get_shard_iterator(\n",
    "        StreamName='cloudbook2',\n",
    "        ShardId=shard['ShardId'],\n",
    "        ShardIteratorType = 'LATEST',\n",
    "        )\n",
    "    iterlist.append({'iterator': iter['ShardIterator']})  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark and Kinesis stream related funtions\n",
    "Our spark-Kinesis pipeline will have four stages.  The first phase creates the RDD in our psudo D-Stream.  \n",
    "\n",
    "1. gather_list(iteratorlist) takes the list of Kinesis stream iterators and pulls all the events since the last call to this function from the stream.  it then updates the iteratorlist with the iterator set to the spot that follows the last one we pulled.  Each event is a binary-encoded json object so it is converted into a full json object and then to a list.  This is done by the function extractData and dictolist() which returns a list of all the events that were just pulled.\n",
    "\n",
    "2. filter_fun(row, sensor, parameter) is used to select the elements of the RDD that correspond to a specific sensor, parameter pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dictolist(row):\n",
    "    nl = []\n",
    "    for key, value in row.items():\n",
    "        nl.append([key,value])\n",
    "    return nl\n",
    "\n",
    "def extractData(res):\n",
    "    #res is the response['Records'] field\n",
    "    lis = []\n",
    "    for rec in res:\n",
    "        data = rec['Data']\n",
    "        arivetime = rec['ApproximateArrivalTimestamp']\n",
    "        item = json.loads(data)\n",
    "        nitem = dictolist(item)\n",
    "        lis.append(nitem[0])\n",
    "    return lis\n",
    "\n",
    "def filter_fun(row, sensor, parameter):\n",
    "    key = sensor+'_'+parameter\n",
    "    print(row)\n",
    "    if row[0] == key:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def gather_list(iterlist):\n",
    "    listforRDD = []\n",
    "    for iter in iterlist:\n",
    "        resp = client.get_records(ShardIterator=iter['iterator'])\n",
    "        listforRDD.append(extractData(resp['Records']))\n",
    "        iter['iterator'] = resp['NextShardIterator']\n",
    "    if listforRDD == []:\n",
    "        return []\n",
    "    else: \n",
    "        return listforRDD[0]\n",
    "\n",
    "#doiter convers a list of the form [x, iterator] to [x, [list of items]]\n",
    "def doiter(row):\n",
    "    l = []\n",
    "    if row == []:\n",
    "        return []\n",
    "    else:\n",
    "        for it in row[1]:\n",
    "            l.append(it)\n",
    "        return [row[0], l]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datarecorder is a class for creating objects that are used to keep a record a stream\n",
    "\n",
    "It has one main method: record_newlist( newlist) which takes a list of event records of the form \n",
    "(timestamp, value) and appends it to self.datalist which is the record of the stream.  In addition to this record we will use the recent history of the stream to signal unexpected changes in the stream such as anomolies or other major changes in behavior.   However, some instrument streams can be very noisy and we must look for ways to filter the noise to see the significant changes in behavior.\n",
    "\n",
    "To filter the noise in a stream $x_i$ we can use an exponential based smoothing technique which blends the previous values from the stream to create an artificial stream $s_i$ that tends to a geometric average of past values as follows.   Let $s_0 = x_0$ and use the recurrence \n",
    "$$s_n = (1-\\alpha)x_n + \\alpha s_{n-1} $$\n",
    "where $\\alpha$ is a number between 0 and 1,to define the future values.  Expanding the recurrence we see that\n",
    "$$s_n = (1-\\alpha)X_n + \\alpha (1-\\alpha)x_{n-1} + \\alpha^2 s_{n-2} $$\n",
    "$$s_n = (1-\\alpha)\\sum_{i=0}^{n-1}\\alpha^ix_{n-i}+ \\alpha^nx_0 $$\n",
    "\n",
    "(It is easy to verify that in the case of a constant stream: $x_i=x_0$ for all $i$, then $s_i$ = $x_i$  for all $i$.) However if the stream make a radical change in value then the smooted value will lag behind.   We can use this to signal anomolies and other points of behavior change.   But the problem then becomes how to measure a profound change in behavior in a maner that is distinct from noise.   To do that we can compute the standard deviation and look for departures from our smoothed value that exceed the standard deviation.   \n",
    "\n",
    "We can't truely compute the standard deviation of values in a stream that may dramatically change over time, but we can compute the stadard deviation in a recent window.   Let $buff_i$ for $i=1,M$ be a  record of the \"last\" $M$ stream values.   we can compute the standard deviation $\\sigma$ in this window with\n",
    "$$\\mu = \\frac{1}{M}\\sum_{i=1}^M buff_i$$\n",
    "$$\\sigma = \\sqrt{\\frac{1}{M}\\sum_{i=1}^M (buff_i - \\mu)^2}$$\n",
    "Based on this computation we can look for values of $x_i$ that lay outside the interval $[s_i-k\\sigma, s_i+k\\sigma]$ where $k$ is some value greater than 1.   We use $k=1.3$ here.  While $2\\sigma$ would show us some truely significant outliers, we found the more modest $1.3\\sigma$ worked well.\n",
    "\n",
    "For fun, we also keep a record of $s_i$, $s_i-k\\sigma$ and $s_i+k\\sigma$ that we can plot after we complete the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Datarecorder:\n",
    "    def __init__(self, listname):\n",
    "        self.M = 20\n",
    "        self.databuff = np.empty(self.M)\n",
    "        self.itemcnt = 0\n",
    "        self.predicted = []\n",
    "        self.high = []\n",
    "        self.low = []\n",
    "        self.datalist = []\n",
    "        self.old_smoothed = 0.0\n",
    "        self.smoothed = 0.0\n",
    "        self.alpha = 0.04\n",
    "        self.name = listname\n",
    "        self.sigmaold = 0.0\n",
    "    def record_newlist(self, newlist):\n",
    "        #print newlist\n",
    "        topiclis = self.datalist\n",
    "        if topiclis == None:\n",
    "            topiclis = []\n",
    "        for x in newlist:\n",
    "            if self.itemcnt < 5:\n",
    "                alpha1 = 0.9\n",
    "                if self.itemcnt == 0:\n",
    "                    self.old_smoothed = float(x[1])\n",
    "                    self.databuff[:] = float(x[1])\n",
    "            else:\n",
    "                alpha1 = self.alpha\n",
    "            #print x\n",
    "            self.smoothed = alpha1*float(x[1])+ (1-alpha1)*self.old_smoothed\n",
    "            pr = self.old_smoothed\n",
    "            self.predicted.append([x[0], pr])\n",
    "            self.old_smoothed = self.smoothed\n",
    "            topiclis.append(x)\n",
    "            \n",
    "            #now we will compute a smoothed standard deviation \n",
    "            std_window = 1.3\n",
    "            gama = 0.01\n",
    "            sigmasq = 0.0\n",
    "            mu = 0.0\n",
    "            for j in range(self.M):\n",
    "                mu += self.databuff[j]\n",
    "            mu = mu/self.M\n",
    "            for j in range(self.M):\n",
    "                sigmasq += (self.databuff[j]-mu)**2\n",
    "            self.databuff[self.itemcnt%self.M] = x[1]\n",
    "            sigma = np.sqrt(sigmasq)\n",
    "            sigma = gama*sigma + (1-gama)*self.sigmaold\n",
    "            self.sigmaold = sigma\n",
    "            low = pr - std_window*sigma\n",
    "            high= pr + std_window*sigma\n",
    "            self.low.append([x[0], low])\n",
    "            self.high.append([x[0], high])\n",
    "            #print('sigma = %f  low = %f high = %f'%(sigma, low, high))\n",
    "            if (self.itemcnt > 50*self.M) and ((x[1]> high) or (x[1]< low)):\n",
    "                print(\"anomoly at time %s\"%x[0])\n",
    "            self.itemcnt += 1\n",
    "        self.datalist = topiclis\n",
    "# plot the record of the stream as well as the predicted(smoothed) stream and the high and low bounds.\n",
    "    def plotdata(self):\n",
    "        data = {'date': [x[0] for x in self.datalist],\n",
    "                'value': [x[1]for x in self.datalist]}\n",
    "        #print data\n",
    "        df = pd.DataFrame(data, columns = ['date', 'value'])\n",
    "        #print df\n",
    "        tvas = pd.to_datetime(df['date'])\n",
    "        v = pd.to_numeric(df['value'])\n",
    "\n",
    "        data = {'date': [x[0] for x in self.predicted],\n",
    "                'value': [x[1] for x in self.predicted]}\n",
    "        dfpred = pd.DataFrame(data, columns = ['date', 'value'])\n",
    "        tvaspred = pd.to_datetime(dfpred['date'])\n",
    "        vpred = pd.to_numeric(dfpred['value'])\n",
    "\n",
    "        data = {'date': [x[0] for x in self.low],\n",
    "                'value': [x[1] for x in self.low]}\n",
    "        dflow = pd.DataFrame(data, columns = ['date', 'value'])\n",
    "        tvaslow = pd.to_datetime(dflow['date'])\n",
    "        vlow = pd.to_numeric(dflow['value'])\n",
    "\n",
    "        data = {'date': [x[0] for x in self.high],\n",
    "                'value': [x[1] for x in self.high]}\n",
    "        dfhigh = pd.DataFrame(data, columns = ['date', 'value'])\n",
    "        tvashigh = pd.to_datetime(dfhigh['date'])\n",
    "        vhigh = pd.to_numeric(dfhigh['value'])\n",
    "\n",
    "        rcParams['figure.figsize'] = 20, 5\n",
    "        with plot.style.context('fivethirtyeight'):\n",
    "            plot.plot(tvas, v, linewidth = 2)\n",
    "            plot.plot(tvaspred, vpred, linewidth = 2)\n",
    "            plot.plot(tvaslow, vlow, linewidth = 2)\n",
    "            plot.plot(tvashigh, vhigh, linewidth = 2)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we will look at two out of 40 streams\n",
    "by creating a dictionary of the data recoders for each stream of interest.   The ones we have chosen show some interesting behavior that we can track.   One is a chemistry sensor that tracks atmospheric $no_2$ a common polutant and the other sensor is just an ambient temperature sensor.  \n",
    "\n",
    "The function update_records(newlist) takes a list of the form\n",
    "<pre>\n",
    "[ [sensor-name, [[time-stamp, value], [time-stamp, value] .... ]\n",
    "  [sensor-name, [[time-stamp, value], [time-stamp, value] .... ]\n",
    "  ..\n",
    " ]\n",
    "</pre>\n",
    "and uses the dictionary to select the correct recorder and pass the timestamp, value list to the recorder function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "myrecorder = {}\n",
    "myrecorder['Chemsense_no2'] = Datarecorder('Chemsense_no2')\n",
    "myrecorder['TSYS01_temperature'] = Datarecorder('TSYS01_temperature')\n",
    "\n",
    "def update_recorders(newlist):\n",
    "    if newlist != None and newlist != []:\n",
    "        #print newlist\n",
    "        for x in newlist:\n",
    "            print(\"updating list for %s\"%x[0])            \n",
    "            myrecorder[x[0]].record_newlist(x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the main loop\n",
    "Using a seperate process we push the 40 synthetic sensor streams to the Kinesis shard.   The loop below emulates a sparkstreaming use case.  Approximately every 20 seconds we gather all available events from the kinesis stream and then create a spark RDD for them called $data$.   Each event is a list of the form\n",
    "<pre>\n",
    "[sensor-name, [timestamp, value]]\n",
    "</pre>\n",
    "The first step in the pipeline filters all events except those we are interested in keeping.  \n",
    "\n",
    "The second step groups the events by the sensor-name key in the tuple.  this results in a list with two elements\n",
    "<pre>\n",
    "[['Chemsense-no2', [python-interator over the (time-stamp, value) tuples]],\n",
    " ['TSY01-temperature', [python-iterator over the (time-stamp, value) tuples]\n",
    "]\n",
    "</pre>\n",
    "The third step uses map to conver the python interators into explicit lists.\n",
    "\n",
    "Finally we collect this into a list $newlist$ which we pass to the recorders to record and look for events of interest.\n",
    "\n",
    "Note that the data in the data set covers 24 hours of real data where the instruments sent an event approxilately every 25 seconds. This is approximately 2 events per minute for a total of approximately 3450 for the full day. All together there are 172,800 events in the dataset and the total size is approximaately 14MB.   We are pushing this all to Kinesis in about $120*20 seconds = 40$ minutes using one shard.  We could do it much faster with 2 shards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating list for TSYS01_temperature\n",
      "**********  end of gather 0 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 1 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 2 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 3 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 4 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 5 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 6 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 7 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 8 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 9 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 10 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 11 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 12 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 13 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 14 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 15 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 16 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 17 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 18 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 19 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 20 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 21 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 22 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 23 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 24 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 25 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 26 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 27 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 28 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 29 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 30 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 31 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 32 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 33 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 34 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 35 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 36 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 37 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 38 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 39 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 40 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 41 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 42 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 43 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 44 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 45 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 46 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 47 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 48 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 49 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 50 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 51 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 52 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 53 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 54 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 55 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 56 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 57 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 58 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 59 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 60 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 61 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 62 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 63 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 64 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 65 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 66 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 67 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 68 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "anomoly at time 2016-11-10 17:05:06.980000\n",
      "anomoly at time 2016-11-10 17:05:57.049000\n",
      "anomoly at time 2016-11-10 17:06:22.081000\n",
      "anomoly at time 2016-11-10 17:06:47.132000\n",
      "anomoly at time 2016-11-10 17:07:12.172000\n",
      "anomoly at time 2016-11-10 17:07:37.212000\n",
      "anomoly at time 2016-11-10 17:08:02.264000\n",
      "anomoly at time 2016-11-10 17:08:27.321000\n",
      "anomoly at time 2016-11-10 17:08:52.383000\n",
      "anomoly at time 2016-11-10 17:09:17.417000\n",
      "anomoly at time 2016-11-10 17:09:42.453000\n",
      "anomoly at time 2016-11-10 17:10:07.489000\n",
      "anomoly at time 2016-11-10 17:10:57.572000\n",
      "**********  end of gather 69 ***************\n",
      "updating list for TSYS01_temperature\n",
      "anomoly at time 2016-11-10 17:15:57.064000\n",
      "anomoly at time 2016-11-10 17:16:22.100000\n",
      "anomoly at time 2016-11-10 17:17:37.232000\n",
      "anomoly at time 2016-11-10 17:18:02.271000\n",
      "anomoly at time 2016-11-10 17:19:42.442000\n",
      "anomoly at time 2016-11-10 17:20:07.482000\n",
      "anomoly at time 2016-11-10 17:20:32.550000\n",
      "anomoly at time 2016-11-10 17:20:57.582000\n",
      "anomoly at time 2016-11-10 17:21:22.617000\n",
      "anomoly at time 2016-11-10 17:21:47.653000\n",
      "anomoly at time 2016-11-10 17:22:11.685000\n",
      "anomoly at time 2016-11-10 17:22:36.727000\n",
      "anomoly at time 2016-11-10 17:23:01.785000\n",
      "anomoly at time 2016-11-10 17:23:26.843000\n",
      "anomoly at time 2016-11-10 17:23:51.874000\n",
      "anomoly at time 2016-11-10 17:24:16.907000\n",
      "anomoly at time 2016-11-10 17:24:41.951000\n",
      "anomoly at time 2016-11-10 17:25:06.995000\n",
      "anomoly at time 2016-11-10 17:25:32.034000\n",
      "anomoly at time 2016-11-10 17:25:57.090000\n",
      "updating list for Chemsense_no2\n",
      "anomoly at time 2016-11-10 17:11:22.623000\n",
      "anomoly at time 2016-11-10 17:11:47.692000\n",
      "anomoly at time 2016-11-10 17:13:01.802000\n",
      "anomoly at time 2016-11-10 17:13:26.838000\n",
      "anomoly at time 2016-11-10 17:13:51.875000\n",
      "**********  end of gather 70 ***************\n",
      "updating list for TSYS01_temperature\n",
      "anomoly at time 2016-11-10 17:26:22.130000\n",
      "anomoly at time 2016-11-10 17:26:47.162000\n",
      "anomoly at time 2016-11-10 17:27:12.199000\n",
      "anomoly at time 2016-11-10 17:27:37.236000\n",
      "anomoly at time 2016-11-10 17:28:02.279000\n",
      "anomoly at time 2016-11-10 17:28:27.322000\n",
      "anomoly at time 2016-11-10 17:28:52.363000\n",
      "anomoly at time 2016-11-10 17:29:17.405000\n",
      "anomoly at time 2016-11-10 17:29:42.460000\n",
      "anomoly at time 2016-11-10 17:30:07.507000\n",
      "anomoly at time 2016-11-10 17:30:32.595000\n",
      "anomoly at time 2016-11-10 17:30:57.637000\n",
      "anomoly at time 2016-11-10 17:31:22.675000\n",
      "anomoly at time 2016-11-10 17:31:47.740000\n",
      "anomoly at time 2016-11-10 17:32:11.786000\n",
      "anomoly at time 2016-11-10 17:32:36.824000\n",
      "anomoly at time 2016-11-10 17:33:01.864000\n",
      "anomoly at time 2016-11-10 17:33:26.909000\n",
      "anomoly at time 2016-11-10 17:33:51.942000\n",
      "anomoly at time 2016-11-10 17:34:16.984000\n",
      "anomoly at time 2016-11-10 17:35:57.144000\n",
      "anomoly at time 2016-11-10 17:36:22.179000\n",
      "anomoly at time 2016-11-10 17:36:47.244000\n",
      "anomoly at time 2016-11-10 17:37:12.305000\n",
      "anomoly at time 2016-11-10 17:37:37.412000\n",
      "anomoly at time 2016-11-10 17:38:02.456000\n",
      "anomoly at time 2016-11-10 17:39:17.570000\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 71 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 72 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 73 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 74 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 75 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 76 ***************\n",
      "updating list for TSYS01_temperature\n",
      "anomoly at time 2016-11-10 00:00:16.860000\n",
      "anomoly at time 2016-11-10 00:00:41.930000\n",
      "anomoly at time 2016-11-10 00:01:05.977000\n",
      "anomoly at time 2016-11-10 00:01:31.025000\n",
      "anomoly at time 2016-11-10 00:01:56.134000\n",
      "anomoly at time 2016-11-10 00:02:21.181000\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 77 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 78 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 79 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 80 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 81 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 82 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 83 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 84 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 85 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 86 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 87 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 88 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 89 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 90 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 91 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 92 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 93 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 94 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 95 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 96 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 97 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 98 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 99 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 100 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 101 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 102 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 103 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 104 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 105 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 106 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 107 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 108 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 109 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 110 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 111 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 112 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 113 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 114 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 115 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 116 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 117 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 118 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 119 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 120 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 121 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 122 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 123 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 124 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 125 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 126 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 127 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 128 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 129 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 130 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 131 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 132 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 133 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 134 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 135 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 136 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 137 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 138 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 139 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 140 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 141 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 142 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 143 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 144 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 145 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 146 ***************\n",
      "updating list for TSYS01_temperature\n",
      "updating list for Chemsense_no2\n",
      "anomoly at time 2016-11-10 17:05:06.980000\n",
      "anomoly at time 2016-11-10 17:05:57.049000\n",
      "anomoly at time 2016-11-10 17:06:22.081000\n",
      "anomoly at time 2016-11-10 17:06:47.132000\n",
      "anomoly at time 2016-11-10 17:07:12.172000\n",
      "anomoly at time 2016-11-10 17:07:37.212000\n",
      "anomoly at time 2016-11-10 17:08:02.264000\n",
      "anomoly at time 2016-11-10 17:08:27.321000\n",
      "anomoly at time 2016-11-10 17:08:52.383000\n",
      "anomoly at time 2016-11-10 17:09:17.417000\n",
      "anomoly at time 2016-11-10 17:09:42.453000\n",
      "anomoly at time 2016-11-10 17:10:07.489000\n",
      "anomoly at time 2016-11-10 17:10:57.572000\n",
      "**********  end of gather 147 ***************\n",
      "updating list for TSYS01_temperature\n",
      "anomoly at time 2016-11-10 17:15:57.064000\n",
      "anomoly at time 2016-11-10 17:16:22.100000\n",
      "anomoly at time 2016-11-10 17:17:37.232000\n",
      "anomoly at time 2016-11-10 17:18:02.271000\n",
      "anomoly at time 2016-11-10 17:19:42.442000\n",
      "anomoly at time 2016-11-10 17:20:07.482000\n",
      "anomoly at time 2016-11-10 17:20:32.550000\n",
      "anomoly at time 2016-11-10 17:20:57.582000\n",
      "anomoly at time 2016-11-10 17:21:22.617000\n",
      "anomoly at time 2016-11-10 17:21:47.653000\n",
      "anomoly at time 2016-11-10 17:22:11.685000\n",
      "anomoly at time 2016-11-10 17:22:36.727000\n",
      "anomoly at time 2016-11-10 17:23:01.785000\n",
      "anomoly at time 2016-11-10 17:23:26.843000\n",
      "anomoly at time 2016-11-10 17:23:51.874000\n",
      "anomoly at time 2016-11-10 17:24:16.907000\n",
      "anomoly at time 2016-11-10 17:24:41.951000\n",
      "anomoly at time 2016-11-10 17:25:06.995000\n",
      "updating list for Chemsense_no2\n",
      "anomoly at time 2016-11-10 17:11:22.623000\n",
      "anomoly at time 2016-11-10 17:11:47.692000\n",
      "anomoly at time 2016-11-10 17:13:01.802000\n",
      "anomoly at time 2016-11-10 17:13:26.838000\n",
      "anomoly at time 2016-11-10 17:13:51.875000\n",
      "**********  end of gather 148 ***************\n",
      "updating list for TSYS01_temperature\n",
      "anomoly at time 2016-11-10 17:25:32.034000\n",
      "anomoly at time 2016-11-10 17:25:57.090000\n",
      "anomoly at time 2016-11-10 17:26:22.130000\n",
      "anomoly at time 2016-11-10 17:26:47.162000\n",
      "anomoly at time 2016-11-10 17:27:12.199000\n",
      "anomoly at time 2016-11-10 17:27:37.236000\n",
      "anomoly at time 2016-11-10 17:28:02.279000\n",
      "anomoly at time 2016-11-10 17:28:27.322000\n",
      "anomoly at time 2016-11-10 17:28:52.363000\n",
      "anomoly at time 2016-11-10 17:29:17.405000\n",
      "anomoly at time 2016-11-10 17:29:42.460000\n",
      "anomoly at time 2016-11-10 17:30:07.507000\n",
      "anomoly at time 2016-11-10 17:30:32.595000\n",
      "anomoly at time 2016-11-10 17:30:57.637000\n",
      "anomoly at time 2016-11-10 17:31:22.675000\n",
      "anomoly at time 2016-11-10 17:31:47.740000\n",
      "anomoly at time 2016-11-10 17:32:11.786000\n",
      "anomoly at time 2016-11-10 17:32:36.824000\n",
      "anomoly at time 2016-11-10 17:33:01.864000\n",
      "anomoly at time 2016-11-10 17:33:26.909000\n",
      "anomoly at time 2016-11-10 17:33:51.942000\n",
      "anomoly at time 2016-11-10 17:34:16.984000\n",
      "anomoly at time 2016-11-10 17:35:57.144000\n",
      "anomoly at time 2016-11-10 17:36:22.179000\n",
      "anomoly at time 2016-11-10 17:36:47.244000\n",
      "anomoly at time 2016-11-10 17:37:12.305000\n",
      "anomoly at time 2016-11-10 17:37:37.412000\n",
      "anomoly at time 2016-11-10 17:38:02.456000\n",
      "anomoly at time 2016-11-10 17:39:17.570000\n",
      "updating list for Chemsense_no2\n",
      "**********  end of gather 149 ***************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(150):\n",
    "    gathered = gather_list(iterlist)\n",
    "    data = sc.parallelize(gathered, 2)\n",
    "    newlist = data.filter(lambda p: filter_fun(p, 'Chemsense', 'no2') \n",
    "                                 or filter_fun(p,'TSYS01','temperature')) \\\n",
    "                  .groupByKey()                                            \\\n",
    "                  .map(lambda p: doiter(p))                                \\\n",
    "                  .collect()\n",
    "    update_recorders(newlist)\n",
    "    print('**********  end of gather %s ***************'%i)\n",
    "    time.sleep(20.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  the following is edited output from the above.  The first 80 event gatherings have been deleted because nothing happened.\n",
    "\n",
    "you will notice that the first anomolies occur for the Chemsense_no2 detector at 17:05 and persist until 17:13.  For the temperature sensor the anomolies start at 17:15 and continue to go to 17:39.   The temperature sensor continues to see strange spikes around 23:03 and continue for another 14 minutes.  \n",
    "\n",
    "<pre>\n",
    "**********  end of gather 80 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 81 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 82 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 83 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 84 ***************\n",
    "updating list for Chemsense_no2\n",
    "anomoly at time 2016-11-10 17:05:06.980000\n",
    "anomoly at time 2016-11-10 17:05:57.049000\n",
    "anomoly at time 2016-11-10 17:06:22.081000\n",
    "anomoly at time 2016-11-10 17:06:47.132000\n",
    "anomoly at time 2016-11-10 17:07:12.172000\n",
    "anomoly at time 2016-11-10 17:07:37.212000\n",
    "anomoly at time 2016-11-10 17:08:02.264000\n",
    "anomoly at time 2016-11-10 17:08:27.321000\n",
    "anomoly at time 2016-11-10 17:08:52.383000\n",
    "anomoly at time 2016-11-10 17:09:17.417000\n",
    "anomoly at time 2016-11-10 17:09:42.453000\n",
    "anomoly at time 2016-11-10 17:10:07.489000\n",
    "anomoly at time 2016-11-10 17:10:57.572000\n",
    "anomoly at time 2016-11-10 17:11:22.623000\n",
    "anomoly at time 2016-11-10 17:11:47.692000\n",
    "anomoly at time 2016-11-10 17:13:01.802000\n",
    "anomoly at time 2016-11-10 17:13:26.838000\n",
    "anomoly at time 2016-11-10 17:13:51.875000\n",
    "updating list for TSYS01_temperature\n",
    "anomoly at time 2016-11-10 17:15:57.064000\n",
    "anomoly at time 2016-11-10 17:16:22.100000\n",
    "anomoly at time 2016-11-10 17:17:37.232000\n",
    "**********  end of gather 85 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "anomoly at time 2016-11-10 17:18:02.271000\n",
    "anomoly at time 2016-11-10 17:19:42.442000\n",
    "anomoly at time 2016-11-10 17:20:07.482000\n",
    "anomoly at time 2016-11-10 17:20:32.550000\n",
    "anomoly at time 2016-11-10 17:20:57.582000\n",
    "anomoly at time 2016-11-10 17:21:22.617000\n",
    "anomoly at time 2016-11-10 17:21:47.653000\n",
    "anomoly at time 2016-11-10 17:22:11.685000\n",
    "anomoly at time 2016-11-10 17:22:36.727000\n",
    "anomoly at time 2016-11-10 17:23:01.785000\n",
    "anomoly at time 2016-11-10 17:23:26.843000\n",
    "anomoly at time 2016-11-10 17:23:51.874000\n",
    "anomoly at time 2016-11-10 17:24:16.907000\n",
    "anomoly at time 2016-11-10 17:24:41.951000\n",
    "anomoly at time 2016-11-10 17:25:06.995000\n",
    "anomoly at time 2016-11-10 17:25:32.034000\n",
    "anomoly at time 2016-11-10 17:25:57.090000\n",
    "anomoly at time 2016-11-10 17:26:22.130000\n",
    "anomoly at time 2016-11-10 17:26:47.162000\n",
    "anomoly at time 2016-11-10 17:27:12.199000\n",
    "anomoly at time 2016-11-10 17:27:37.236000\n",
    "anomoly at time 2016-11-10 17:28:02.279000\n",
    "anomoly at time 2016-11-10 17:28:27.322000\n",
    "anomoly at time 2016-11-10 17:28:52.363000\n",
    "anomoly at time 2016-11-10 17:29:17.405000\n",
    "anomoly at time 2016-11-10 17:29:42.460000\n",
    "anomoly at time 2016-11-10 17:30:07.507000\n",
    "**********  end of gather 86 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "anomoly at time 2016-11-10 17:30:32.595000\n",
    "anomoly at time 2016-11-10 17:30:57.637000\n",
    "anomoly at time 2016-11-10 17:31:22.675000\n",
    "anomoly at time 2016-11-10 17:31:47.740000\n",
    "anomoly at time 2016-11-10 17:32:11.786000\n",
    "anomoly at time 2016-11-10 17:32:36.824000\n",
    "anomoly at time 2016-11-10 17:33:01.864000\n",
    "anomoly at time 2016-11-10 17:33:26.909000\n",
    "anomoly at time 2016-11-10 17:33:51.942000\n",
    "anomoly at time 2016-11-10 17:34:16.984000\n",
    "anomoly at time 2016-11-10 17:35:57.144000\n",
    "anomoly at time 2016-11-10 17:36:22.179000\n",
    "anomoly at time 2016-11-10 17:36:47.244000\n",
    "anomoly at time 2016-11-10 17:37:12.305000\n",
    "anomoly at time 2016-11-10 17:37:37.412000\n",
    "anomoly at time 2016-11-10 17:38:02.456000\n",
    "anomoly at time 2016-11-10 17:39:17.570000\n",
    "**********  end of gather 87 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 88 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 89 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 90 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 91 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 92 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 93 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 94 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 95 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 96 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 97 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 98 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 99 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 100 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 101 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 102 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 103 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 104 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 105 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 106 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 107 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 108 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "anomoly at time 2016-11-10 22:16:26.707000\n",
    "anomoly at time 2016-11-10 22:16:51.752000\n",
    "anomoly at time 2016-11-10 22:17:16.804000\n",
    "anomoly at time 2016-11-10 22:17:41.851000\n",
    "anomoly at time 2016-11-10 22:18:06.893000\n",
    "anomoly at time 2016-11-10 22:18:31.940000\n",
    "anomoly at time 2016-11-10 22:19:22.065000\n",
    "anomoly at time 2016-11-10 22:20:37.233000\n",
    "anomoly at time 2016-11-10 22:21:02.302000\n",
    "**********  end of gather 109 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "anomoly at time 2016-11-10 22:23:07.533000\n",
    "anomoly at time 2016-11-10 22:23:32.592000\n",
    "anomoly at time 2016-11-10 22:24:22.673000\n",
    "anomoly at time 2016-11-10 22:25:37.789000\n",
    "anomoly at time 2016-11-10 22:26:51.921000\n",
    "anomoly at time 2016-11-10 22:27:17.973000\n",
    "anomoly at time 2016-11-10 22:27:42.023000\n",
    "anomoly at time 2016-11-10 22:28:07.069000\n",
    "anomoly at time 2016-11-10 22:28:32.142000\n",
    "anomoly at time 2016-11-10 22:28:57.174000\n",
    "**********  end of gather 110 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 111 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 112 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "anomoly at time 2016-11-10 23:03:07.733000\n",
    "anomoly at time 2016-11-10 23:03:32.768000\n",
    "anomoly at time 2016-11-10 23:03:57.803000\n",
    "anomoly at time 2016-11-10 23:04:22.871000\n",
    "anomoly at time 2016-11-10 23:04:47.934000\n",
    "anomoly at time 2016-11-10 23:05:13.968000\n",
    "anomoly at time 2016-11-10 23:05:38.012000\n",
    "anomoly at time 2016-11-10 23:06:03.049000\n",
    "anomoly at time 2016-11-10 23:08:58.305000\n",
    "anomoly at time 2016-11-10 23:09:23.343000\n",
    "**********  end of gather 113 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "anomoly at time 2016-11-10 23:09:48.378000\n",
    "anomoly at time 2016-11-10 23:12:43.730000\n",
    "anomoly at time 2016-11-10 23:14:47.974000\n",
    "anomoly at time 2016-11-10 23:17:18.233000\n",
    "**********  end of gather 114 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 115 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 116 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 117 ***************\n",
    "updating list for Chemsense_no2\n",
    "updating list for TSYS01_temperature\n",
    "**********  end of gather 118 ***************\n",
    "**********  end of gather 119 ***************\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each recorder keeps track of the data, \n",
    "and the smoothed prediction and the $3\\sigma$-wide saftey widow.  The plot function will show the history.  One can clearly see the periods of strange behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "myrecorder['Chemsense_no2'].plotdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "myrecorder['TSYS01_temperature'].plotdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7 - Spark (local)",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
